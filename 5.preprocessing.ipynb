{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 데이터 가공(LDA 추가 전)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('E:/data20200301.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_date = [x for x in list(df.columns) if '2020' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(df, columns=['notice_num','nick','mail','phone_fin',\n",
    "                                'date','hour','minute','day',\n",
    "                                'price','safe_phone',\n",
    "                                'title','text',\n",
    "                                'img_count','img_source',\n",
    "                                ].extend(f_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = list(df2['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['year'] = pd.Series([x.split('.')[0] for x in date])\n",
    "#df2['month']= pd.Series([x.split('.')[1] for x in date])\n",
    "#df2['days'] = pd.Series([x.split('.')[2] for x in date])\n",
    "df2['date'] = pd.Series([datetime(int(x.split('.')[0]),int(x.split('.')[1]),int(x.split('.')[2])) for x in date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.loc[:,f_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['total'] = 0\n",
    "df3['s_search'] = 0\n",
    "df3['r_search1'] = 0\n",
    "df3['r_search2'] = 0\n",
    "df3['r_search3'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-18eaeede084c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['total'][i] = v\n",
      "C:\\Users\\dong\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "<ipython-input-9-18eaeede084c>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['s_search'][i] = datetime(2020,2,2) + relativedelta(days=len(v), months=-3)\n",
      "<ipython-input-9-18eaeede084c>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['r_search1'][i] = v[-1]\n",
      "<ipython-input-9-18eaeede084c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['r_search2'][i] = v[-2]\n",
      "<ipython-input-9-18eaeede084c>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['r_search3'][i] = v[-3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df3)):\n",
    "    v = list(df3.iloc[i,0:len(f_date)])\n",
    "    df3['total'][i] = v\n",
    "    v_ = v.copy()\n",
    "    v_.reverse()\n",
    "    df3['s_search'][i] = datetime(2020,2,2) + relativedelta(days=len(v), months=-3)\n",
    "    #df3['s_search'][i] = datetime(2020,2,2) + relativedelta(days=len(v) - v_.index('없음'),months=-3)\n",
    "    df3['r_search1'][i] = v[-1]\n",
    "    df3['r_search2'][i] = v[-2]\n",
    "    df3['r_search3'][i] = v[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = list(df3['total'])\n",
    "s_search = list(df3['s_search'])\n",
    "r_search1 = list(df3['r_search1'])\n",
    "r_search2 = list(df3['r_search2'])\n",
    "r_search3 = list(df3['r_search3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Fraud'] = pd.Series([x for x in total])\n",
    "df2['s_search'] = pd.Series([x for x in s_search])\n",
    "df2['r_search1'] = pd.Series([x for x in r_search1])\n",
    "df2['r_search2'] = pd.Series([x for x in r_search2])\n",
    "df2['r_search3'] = pd.Series([x for x in r_search3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df2.drop(f_date,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['Final'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.loc[(df4['date'] >= df4['s_search']) & (df4['r_search1'] == \"Y\") & (df4['r_search2'] == \"Y\") & (df4['r_search3'] == \"Y\"),['Final']] = \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.loc[df4['Final'] == 0 ,['Final']] = \"N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Final]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.loc[df4['Final'] == 0 ,['Final']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dong\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pandas import Series\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "scaler = RobustScaler()\n",
    "#scaler = StandardScaler()\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import konlpy\n",
    "from konlpy.tag import Okt, Komoran\n",
    "okt = Okt()\n",
    "kmr = Komoran(userdic='/tmp/dic.txt')\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import warnings\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "## import pyLDAvis.gensim as gensimvis\n",
    "## import pyLDAvis\n",
    "\n",
    "from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def deEmojify(inputString):\n",
    "    return str(inputString.encode('CP949', 'ignore').decode('CP949'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizing\n",
    "def preprocess(t):\n",
    "    #token = okt.morphs(str(t).strip().replace('  ',''), stem = True)\n",
    "    #prep = [word for word in token if not word in stop_words]\n",
    "    \n",
    "    #token = okt.pos(str(t), norm=True, stem = True)\n",
    "    try:\n",
    "        token = kmr.pos(deEmojify(\" \".join(str(t).splitless())))\n",
    "    except:\n",
    "        token = okt.pos(str(t))\n",
    "        \n",
    "    prep = [word for word, pos in token if pos in p]\n",
    "    \n",
    "    return prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = ['Noun','Verb','Adjective','Adverb'] #okt\n",
    "\n",
    "#p = ['NNG','NNP','NNB','NR','NP','VV','VA','MAG','MAJ',\n",
    "#     'Noun','Verb','Adjective','Adverb'] #kmr\n",
    "\n",
    "n = ['Noun']\n",
    "\n",
    "v = ['Verb']\n",
    "\n",
    "aj = ['Adjective']\n",
    "\n",
    "av = ['Adverb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenizing\n",
    "def preprocess(t):\n",
    "    token = okt.pos(str(t), norm=True, stem = True)\n",
    "    ## len(token)\n",
    "    if len(token) == 0:\n",
    "        pp_n.append(0)\n",
    "        pp_v.append(0)\n",
    "        pp_aj.append(0)\n",
    "        pp_av.append(0)\n",
    "    else:\n",
    "        pp_n.append(len([word for word, pos in token if pos in n])/len(token))\n",
    "        pp_v.append(len([word for word, pos in token if pos in n])/len(token))\n",
    "        pp_aj.append(len([word for word, pos in token if pos in n])/len(token))\n",
    "        pp_av.append(len([word for word, pos in token if pos in n])/len(token))\n",
    "            \n",
    "    p_n.append([word for word, pos in token if pos in n])\n",
    "    p_v.append([word for word, pos in token if pos in v])\n",
    "    p_aj.append([word for word, pos in token if pos in aj])\n",
    "    p_av.append([word for word, pos in token if pos in av])\n",
    "           \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145536\n",
      "145536 145536\n",
      "145536 145536\n",
      "145536 145536\n",
      "145536 145536\n"
     ]
    }
   ],
   "source": [
    "p_n = []\n",
    "p_v = []\n",
    "p_aj = []\n",
    "p_av = []\n",
    "pp_n = []\n",
    "pp_v = []\n",
    "pp_aj = []\n",
    "pp_av = []\n",
    "\n",
    "print(len(raw['text']))\n",
    "raw['text'].apply(lambda x: preprocess(x))\n",
    "print(len(p_n),len(pp_n))\n",
    "print(len(p_v),len(pp_v))\n",
    "print(len(p_aj),len(pp_aj))\n",
    "print(len(p_av),len(pp_av))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tag = p_aj\n",
    "dictionary = Dictionary(tag)\n",
    "pre_corpus = [dictionary.doc2bow(text) for text in tag]\n",
    "model = TfidfModel(pre_corpus)\n",
    "corpus = Series(pre_corpus).apply(lambda x: model[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for n in [2,3,4,5,6,7,8,9,10,11,12,13,14,15]:\n",
    "    lda = LdaModel(corpus, id2word=dictionary, num_topics=n, alpha = 0.1, eta = 50/n, eval_every = -1, passes=10, random_state = 1)\n",
    "    print('\\n',n, '개의 주제로 나눴을 경우','\\nPerplexity: ', lda.log_perplexity(corpus),)\n",
    "    coherence_model_lda = CoherenceModel(model=lda, texts=tag, dictionary=dictionary, coherence='c_v')\n",
    "    print('Coherence Score: ', coherence_model_lda.get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n = 2\n",
    "lda = LdaModel(corpus, id2word=dictionary, num_topics=n, alpha = 0.1, eta = 50/n, eval_every = -1, passes=10, random_state = 1)\n",
    "\n",
    "lda_topic = lda.print_topics(num_topics=n, num_words=10)\n",
    "f = open(\"lda.txt\", 'w', -1, \"utf-8\")\n",
    "count = 1\n",
    "for i in lda_topic:\n",
    "    f.write('---- {}번째 주제 -----\\n'.format(count))\n",
    "    print('\\n---- {}번째 주제 -----'.format(count))\n",
    "    count += 1\n",
    "    b = i[1].split('+')\n",
    "    for c in b:\n",
    "        [value, word] = c.split('*')\n",
    "        f.write('{}:\\t{}\\n'.format(word.split('\"')[1], value.split(\"'\")[0].strip()))\n",
    "        print('{}:\\t{}'.format(word.split('\"')[1], value.split(\"'\")[0].strip()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n\n",
      "\n",
      "---- 1번째 주제 -----\n",
      "상품:\t0.005\n",
      "사이즈:\t0.005\n",
      "상태:\t0.005\n",
      "용감:\t0.005\n",
      "문자:\t0.004\n",
      "택포:\t0.004\n",
      "문의:\t0.004\n",
      "가죽:\t0.003\n",
      "구매:\t0.003\n",
      "판매:\t0.003\n",
      "\n",
      "---- 2번째 주제 -----\n",
      "제품:\t0.006\n",
      "판매:\t0.005\n",
      "연락:\t0.004\n",
      "구매:\t0.004\n",
      "직거래:\t0.004\n",
      "가격:\t0.004\n",
      "택배:\t0.004\n",
      "거래:\t0.004\n",
      "지갑:\t0.004\n",
      "구입:\t0.004\n",
      "\n",
      "v\n",
      "\n",
      "---- 1번째 주제 -----\n",
      "하다:\t0.128\n",
      "줄다:\t0.118\n",
      "파다:\t0.050\n",
      "드리다:\t0.050\n",
      "되다:\t0.044\n",
      "않다:\t0.036\n",
      "보내다:\t0.033\n",
      "받다:\t0.031\n",
      "바라다:\t0.026\n",
      "보다:\t0.026\n",
      "\n",
      "---- 2번째 주제 -----\n",
      "하다:\t0.040\n",
      "입다:\t0.033\n",
      "되다:\t0.023\n",
      "적다:\t0.022\n",
      "줄다:\t0.021\n",
      "않다:\t0.020\n",
      "드리다:\t0.019\n",
      "되어다:\t0.019\n",
      "들다:\t0.017\n",
      "나오다:\t0.016\n",
      "\n",
      "aj\n",
      "\n",
      "---- 1번째 주제 -----\n",
      "있다:\t0.047\n",
      "이다:\t0.044\n",
      "좋다:\t0.038\n",
      "예쁘다:\t0.037\n",
      "없다:\t0.028\n",
      "가능하다:\t0.027\n",
      "이쁘다:\t0.023\n",
      "아니다:\t0.022\n",
      "부탁드리다:\t0.018\n",
      "고급스럽다:\t0.018\n",
      "\n",
      "---- 2번째 주제 -----\n",
      "이다:\t0.173\n",
      "좋다:\t0.098\n",
      "있다:\t0.097\n",
      "가능하다:\t0.086\n",
      "없다:\t0.071\n",
      "부탁드리다:\t0.063\n",
      "깨끗하다:\t0.037\n",
      "많다:\t0.034\n",
      "원하다:\t0.029\n",
      "신중하다:\t0.028\n",
      "\n",
      "av\n",
      "\n",
      "---- 1번째 주제 -----\n",
      "다:\t0.207\n",
      "너무:\t0.198\n",
      "엄청:\t0.052\n",
      "훨씬:\t0.032\n",
      "함께:\t0.032\n",
      "오래:\t0.025\n",
      "물론:\t0.025\n",
      "혹은:\t0.024\n",
      "풍:\t0.021\n",
      "그래서:\t0.021\n",
      "\n",
      "---- 2번째 주제 -----\n",
      "없이:\t0.210\n",
      "많이:\t0.184\n",
      "같이:\t0.124\n",
      "또는:\t0.102\n",
      "함께:\t0.064\n",
      "딱:\t0.053\n",
      "따로:\t0.049\n",
      "다:\t0.040\n",
      "아직:\t0.024\n",
      "히:\t0.013\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "for name, pre_text in zip(['n','v','aj','av'], [p_n,p_v,p_aj,p_av]):\n",
    "    dictionary = Dictionary(pre_text)\n",
    "    #dictionary.filter_extremes(no_below=2000, no_above=0.5) #TF-IDF로 대체? or같이 사용?\n",
    "    pre_corpus = [dictionary.doc2bow(text) for text in pre_text]\n",
    "    model = TfidfModel(pre_corpus)\n",
    "\n",
    "    corpus = Series(pre_corpus).apply(lambda x: model[x])\n",
    "    print('\\n' + name)\n",
    "    globals()[f'{name}_lda'] = LdaModel(corpus, id2word=dictionary, num_topics=n, alpha = 0.1, eta = 1.5, eval_every = -1, passes=10, random_state = 1)\n",
    "    globals()[f'lda_topic_{name}'] = globals()[f'{name}_lda'].print_topics(num_topics=n, num_words=10)\n",
    "    f = open(\"lda.txt\", 'w', -1, \"utf-8\")\n",
    "    count = 1\n",
    "    for i in globals()[f'lda_topic_{name}']:\n",
    "        f.write('---- {}번째 주제 -----\\n'.format(count))\n",
    "        print('\\n---- {}번째 주제 -----'.format(count))\n",
    "        count += 1\n",
    "        b = i[1].split('+')\n",
    "        for c in b:\n",
    "            [value, word] = c.split('*')\n",
    "            f.write('{}:\\t{}\\n'.format(word.split('\"')[1], value.split(\"'\")[0].strip()))\n",
    "            print('{}:\\t{}'.format(word.split('\"')[1], value.split(\"'\")[0].strip()))\n",
    "    f.close()\n",
    "    globals()[f'topic_probability_mat_{name}'] = globals()[f'{name}_lda'][corpus]\n",
    "    globals()[f'sparse_{name}'] = pd.DataFrame(data = globals()[f'topic_probability_mat_{name}'], columns = range(2))\n",
    "    globals()[f'sparse_{name}'].loc[:,:]=0\n",
    "    for i in range(len(globals()[f'topic_probability_mat_{name}'])):\n",
    "        for (j,x) in globals()[f'topic_probability_mat_{name}'][i]:\n",
    "            globals()[f'sparse_{name}'].loc[i,j] = x\n",
    "    globals()[f'sparse_{name}'].columns = [name+'_1',name+'_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_1</th>\n",
       "      <th>n_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026923</td>\n",
       "      <td>0.973077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0174832</td>\n",
       "      <td>0.982517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0224072</td>\n",
       "      <td>0.977593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0262071</td>\n",
       "      <td>0.973793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.985655</td>\n",
       "      <td>0.0143451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145531</th>\n",
       "      <td>0.972207</td>\n",
       "      <td>0.0277927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145532</th>\n",
       "      <td>0.0260272</td>\n",
       "      <td>0.973973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145533</th>\n",
       "      <td>0.985024</td>\n",
       "      <td>0.0149759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145534</th>\n",
       "      <td>0.0181809</td>\n",
       "      <td>0.981819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145535</th>\n",
       "      <td>0.032941</td>\n",
       "      <td>0.967059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145536 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              n_1        n_2\n",
       "0        0.026923   0.973077\n",
       "1       0.0174832   0.982517\n",
       "2       0.0224072   0.977593\n",
       "3       0.0262071   0.973793\n",
       "4        0.985655  0.0143451\n",
       "...           ...        ...\n",
       "145531   0.972207  0.0277927\n",
       "145532  0.0260272   0.973973\n",
       "145533   0.985024  0.0149759\n",
       "145534  0.0181809   0.981819\n",
       "145535   0.032941   0.967059\n",
       "\n",
       "[145536 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_n.columns = [\"n_1\",\"n_2\"]\n",
    "sparse_v.columns = [\"v_1\",\"v_2\"]\n",
    "sparse_aj.columns = [\"aj_1\",\"aj_2\"]\n",
    "sparse_av.columns = [\"av_1\",\"av_2\"]\n",
    "r_n = pd.DataFrame(data = pp_n, columns = ['r_n'])\n",
    "r_v = pd.DataFrame(data = pp_v, columns = ['r_v'])\n",
    "r_aj = pd.DataFrame(data = pp_aj, columns = ['r_aj'])\n",
    "r_av = pd.DataFrame(data = pp_av, columns = ['r_av'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 마지막 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def spch(Daf):\n",
    "    if len(str(df['text'][i])) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(re.sub(r'\\s','',re.sub(r'\\w','',str(df['text'])))) / len(str(df['text']))\n",
    "    \n",
    "def whsp(Daf):\n",
    "    if len(str(df['text'][i])) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(re.sub(r'\\S','',re.sub(r'\\w','',str(df['text'])))) / len(str(df['text']))\n",
    "\n",
    "def num(Daf):\n",
    "    if len(str(df['text'][i])) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(re.sub(r'\\s','',re.sub(r'\\D','',str(df['text'])))) / len(str(df['text']))\n",
    "\n",
    "def zero(Daf):\n",
    "    return int(str(df['price']).count('0')) / len(str(df['price']))\n",
    "\n",
    "def mail_hide(Daf):\n",
    "    if '*' in df4['mail']:\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "\n",
    "df['ratio_spch'] = df.apply(spch, axis=1)\n",
    "df['ratio_whsp'] = df.apply(whsp, axis=1)\n",
    "df['ratio_num'] = df.apply(num, axis=1)\n",
    "df['price_zero'] = df.apply(zero, axis=1)\n",
    "df['mail_hide'] = df.apply(mail_hide, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-1007c5f81245>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['mail_hide'][i] = 1\n"
     ]
    }
   ],
   "source": [
    "df['mail_hide'] = 0\n",
    "df['len_text'] = 0\n",
    "df['ratio_spch'] = 0\n",
    "df['ratio_whsp'] = 0\n",
    "df['ratio_num'] = 0\n",
    "df['price_zero'] = 0\n",
    "\n",
    "for i in range(len(df['Unnamed: 0'])):\n",
    "    df.loc[i,'price_zero'] = float(str(df['price'][i]).count('0') / len(str(df['price'][i])))\n",
    "    if '*' in df4['mail'][i]:\n",
    "        df['mail_hide'][i] = 1\n",
    "    df.loc[i,'len_text'] = len(str(df['text'][i]))\n",
    "    if len(str(df['text'][i])) != 0:\n",
    "        df.loc[i,'ratio_spch'] = len(re.sub(r'\\s','',re.sub(r'\\w','',str(df['text'][i])))) / len(str(df['text'][i]))\n",
    "        df.loc[i,'ratio_whsp'] = len(re.sub(r'\\S','',str(df['text'][i]))) / len(str(df['text'][i]))\n",
    "        df.loc[i,'ratio_num'] = len(re.sub(r'\\D','',str(df['text'][i]))) / len(str(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_c = ['img_count','len_text','ratio_spch','ratio_whsp','ratio_num','price_zero'] ## 연속형 변수\n",
    "col_n = ['day','grade','hour','mail_hide','safe_phone'] ## 명목형 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Final']== 'Y', ['Final']] = 1\n",
    "df.loc[df['Final']== 'N', ['Final']] = 0\n",
    "Y = df['Final']\n",
    "X = pd.DataFrame(df,columns = col_c + col_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.get_dummies(X.day, prefix='day')\n",
    "B = pd.get_dummies(X.grade, prefix='grade')\n",
    "C = pd.get_dummies(X.hour, prefix='hour')\n",
    "D = pd.get_dummies(X.mail_hide, prefix='hide')\n",
    "E = pd.get_dummies(X.safe_phone, prefix='safe')\n",
    "\n",
    "pro_fin = pd.concat([X.drop(col_n,axis=1),A,B,C,D,E,sparse_n,sparse_v,sparse_aj,sparse_av,r_n,r_v,r_aj,r_av], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(pro_fin, Y, random_state=0)#, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dong\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n",
      "C:\\Users\\dong\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    }
   ],
   "source": [
    "X_train.loc[:,col_c] = scaler.fit_transform(X_train.loc[:,col_c])\n",
    "X_test.loc[:,col_c] = scaler.transform(X_test.loc[:,col_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오버샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '0': 108530\n",
      "After OverSampling, counts of label '1': 622\n"
     ]
    }
   ],
   "source": [
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(Y_train==0)))\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(Y_train==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for n, c in enumerate(list(X_train.columns)):\n",
    "    dic[c] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cf = [list(i.columns) for i in [A,B,C,D,E]]\n",
    "cf = sum(cf,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_nc = SMOTENC(categorical_features=[dic[x] for x in cf], sampling_strategy=0.3, random_state=0)\n",
    "Y_train_r = pd.Series(Y_train.astype('float'))\n",
    "X_res, Y_res = smote_nc.fit_resample(X_train, Y_train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, counts of label '0': 108530\n",
      "After OverSampling, counts of label '1': 32559\n"
     ]
    }
   ],
   "source": [
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(Y_res==0)))\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(Y_res==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colu = list(pro_fin.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res.to_excel('train_X.xlsx')\n",
    "X_test.to_excel('test_X.xlsx')\n",
    "Y_res.to_excel('train_Y.xlsx')\n",
    "Y_test.to_excel('test_Y.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
